# POWER Maintainer: Alexander Baldeck <alex.bldck@gmail.com>
# Maintainer: Bruno Pagani <archange@archlinux.org>
# Maintainer: Jakub Klinkovsk√Ω <lahwaacz at archlinux dot org>

_name=dask
pkgname=python-$_name
pkgver=2026.1.2
pkgrel=1
pkgdesc="Parallel computing with task scheduling"
arch=(any)
url="https://dask.org"
license=(BSD-3-Clause)
depends=(
  python
  python-click
  python-cloudpickle
  python-fsspec
  python-packaging
  python-partd
  python-yaml
  python-toolz
)
makedepends=(
  python-build
  python-installer
  python-setuptools
  python-setuptools-scm
  python-wheel
)
optdepends=(
# https://github.com/dask/dask/blob/main/docs/source/install.rst#optional-dependencies
#  'python-bokeh: visualizing dask diagnostics'
#  'python-cityhash: faster hashing of arrays'
  'python-distributed: distributed computing'
#  'python-fastparquet: storing and reading data from parquet files'
#  'python-gcsfs: file-system interface to Google Cloud Storage'
  'python-graphviz: graph visualization using the graphviz engine'
  'python-jinja: HTML representations of Dask objects in Jupyter notebooks'
  'python-lz4: transparent use of lz4 compression algorithm'
  'python-matplotlib: color map support for graph visualization'
#  'python-murmurhash: faster hashing of arrays'
  'python-numpy: arrays and dataframes support'
  'python-pandas: dataframes support'
  'python-psutil: more accurate CPU count'
  'python-pyarrow: Apache Arrow, for parquet support'
#  'python-s3fs: Amazon S3 support'
  'python-scipy: for dask.array.stats, dask.array.fft, and dask.array.linalg.lu'
  'python-snappy: snappy compression for reading/writing Avro or Parquet files'
#  'python-sparse: use sparse arrays as backend for dask arrays'
  'python-sqlalchemy: writing and reading from SQL databases'
  'python-xarray: N-D labeled arrays and datasets'
  'python-xxhash: faster hashing of arrays'
)
checkdepends=(
  ipython
  python-pytest
  python-pytest-mock
  python-pytest-rerunfailures
  python-pytest-timeout
  python-pytest-xdist
#  python-bokeh
#  python-cityhash
  python-distributed
#  python-fastparquet
#  python-gcsfs
  python-graphviz
  python-jinja
  python-lz4
  python-matplotlib
#  python-murmurhash
  python-numpy
  python-pandas
  python-psutil
  python-pyarrow
#  python-s3fs
  python-scipy
  python-snappy
#  python-sparse
  python-sqlalchemy
  python-xarray
  python-xxhash
)
source=(
  https://github.com/dask/dask/archive/$pkgver/$pkgname-$pkgver.tar.gz
)
b2sums=('461aec2eeef773c599843677e681c3715c474a0b194a9a520033c8b1672568409360715dd46b2111f5f2b5c951ef4a122c1957bd850adb7230326eb1c8971d69')

prepare() {
  cd $_name-$pkgver
  # workaround for failing tests since Python 3.14 (dask.expr objects are not picklable)
  # https://github.com/dask/dask/issues/12043
  sed -i 's|except AttributeError:|except (AttributeError, pickle.PicklingError):|' dask/dataframe/dask_expr/tests/_util.py
}

build() {
  cd $_name-$pkgver
  SETUPTOOLS_SCM_PRETEND_VERSION=$pkgver \
  python -m build --wheel --no-isolation
}

check() {
  local pytest_options=(
    -vv
    --override-ini="addopts="
    -W ignore::DeprecationWarning
    # distribute tests across multiple CPUs
    -n auto
    --dist loadscope
    # use 'signal' which only kills the offending test
    --timeout-method signal
    -k 'not test_RandomState_only_funcs'
    -m 'not network and not slow and not gpu'
    --deselect dask/dataframe/dask_expr/tests/test_shuffle.py::test_set_index_head_nlargest_string
    # skip tests that require zarr (not packaged)
    --deselect dask/array/tests/test_xarray.py::test_xarray_blockwise_fusion_store
    # skip failing test (assert 16 >= 32)
    --deselect dask/tests/test_tokenize.py::test_tokenize_range_index
    # NotImplementedError: (CategoricalDtype(...), array([...], dtype=int8))
    --deselect dask/tests/test_tokenize.py::test_tokenize_pandas
    --deselect dask/tests/test_tokenize.py::test_tokenize_pandas_extension_array
    --deselect dask/dataframe/dask_expr/tests/test_reductions.py::test_cat_value_counts_large_unknown_categories
    # NotImplementedError: (dtype('<M8[ns]'), array([[...]], dtype='datetime64[ns]'))
    --deselect dask/dataframe/dask_expr/tests/test_groupby.py::test_groupby_index_array
    --deselect dask/dataframe/dask_expr/tests/test_shuffle.py::test_set_index_with_dask_dt_index
    --deselect dask/dataframe/io/tests/test_parquet.py::test_pyarrow_schema_inference
    --deselect dask/dataframe/io/tests/test_parquet.py::test_timeseries_nulls_in_schema
    --deselect dask/dataframe/tests/test_groupby.py
    --deselect dask/dataframe/tests/test_shuffle.py
    --deselect dask/dataframe/tseries/tests/test_resample.py::test_resample_pads_last_division_to_avoid_off_by_one
    # Failed: Timeout (>300.0s) from pytest-timeout
    --deselect dask/tests/test_distributed.py::test_futures_in_subgraphs
    --deselect dask/array/tests/test_array_core.py
    # TimeoutError: Test timeout (30) hit after 30.000476195011288s.
    --deselect dask/dataframe/dask_expr/tests/test_distributed.py::test_merge_indicator
    # failing test since Python 3.14 (itertools.chain is not picklable)
    # https://github.com/dask/dask/issues/12042
    --deselect dask/bag/tests/test_bag.py::test_multiple_repartition_partition_size
  )

  cd $_name-$pkgver
  python -m venv --system-site-packages test-env
  test-env/bin/python -m installer dist/*.whl
  test-env/bin/python -m pytest "${pytest_options[@]}"
}

package() {
  cd $_name-$pkgver
  python -m installer --destdir="$pkgdir" dist/*.whl
  install -Dm644 LICENSE.txt -t "$pkgdir"/usr/share/licenses/$pkgname/
}
